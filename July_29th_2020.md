1. I used an article from both Fox News and CNN News. Both titles were not sarcastic in my opinion and the sarcasm detector thought the same as well. It was less sure about the CNN article which I could understand how it could view the CNN article as sarcastic.

[[6.4703119e-07] [3.8864329e-03]]



2. First the text is vectorized and split into sequences. Part of the data is then trained with a model that uses embedding layers which helps the computer establish meaning with word. Then it uses all of the information to produce the next likely letter for each word. In my opinion the model does not do  bad job, it has some spelling errors, but you can make it what it is trying to say.

First generation:

ROMEO: the executioner, to make you with giving acquaint no min that you are coming; And thus name the matter fight against thine ean, Dull catchates; though they are coming.

Second generation:

ROMEO: nst be not this?

PAULINA: The man changes of the remedy amonghts him? Third My Church regroess. Andily from me alone.

PETRUCHIO: Sir, let me speak. First Lord: My no senses with daggges hope; And pity saw it; I know not sphate peace! Wive wag thy sudden sides, yet it shall breat the mind Enclinese thee ouch dead, and hath this young gracious spirit. 

PETRUCHIO: Prithee, belike! Who but remember him, or from my foot for one.

3. translate(u'hace mucho frio aqui.')

   Predicted translation: it s too cold here 

   Real translation: It's really cold here

   Very similar

   translate(u'esta es mi vida.')

   Predicted translation: this is my life

   Real translation: this is my life

   exact

   translate(u'Â¿todavia estan en casa?')

   Predicted translation: are you still at home

   Real translation: are they still home

   Very similar same sentiment

   translate(u'trata de averiguarlo.')

   Predicted translation: try to figure it out

   Real translation: try to find out

   Very accurate same meaning