A One-hot-encoded column turns categorical variables into a form that could be provided to ML algorithms to do a better job in prediction. It turns categorical values into 0s or 1s. The values are discrete.

A dense feature inspects the result of a feature column and inspects categorical columns by transforming it to an indicator column first. It also specifies the absence of data by putting a 0 if data is absent or cannot be represented numerically. This can be useful because missing data can mess up a model.

Logistic Regression Histogram:

![log25.png](https://i.loli.net/2020/07/26/Rh6qwkSt4luJBrp.png)

Boosted Tree Histogram:

![pp125boost.png](https://i.loli.net/2020/07/26/CRDUoh6nmte8PiH.png)

Both together:

![both.png](https://i.loli.net/2020/07/26/l5GkZJ637hu1oAD.png)

The boosted tree histogram has the mortality rate as being higher.

![roccur.png](https://i.loli.net/2020/07/26/bhmRPoGZl21CjXt.png)

The curve above shows that the model is slightly overfitting, but the area under the curve takes up the majority of the graph which is a positive.

The plots below show that age and sex were both extremely high factors in choosing who would die or not. Paying more for a ticket also seems as if your rate of survival was much higher.

![2color.png](https://i.loli.net/2020/07/26/apHlnDFvJIuWEmN.png)

![vilolinplot.png](https://i.loli.net/2020/07/26/wMPnSB5gJtQ8FKA.png)

For me, Sex and Fare were the most important.

![permfeat.png](https://i.loli.net/2020/07/26/ndT86ekv9MfxGRm.png)

![gainfeat.png](https://i.loli.net/2020/07/26/B5mPMKJAYqvz9LO.png)

